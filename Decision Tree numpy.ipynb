{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv('data hw2.csv', header = None)\n",
    "\n",
    "data.head()\n",
    "\n",
    "data = np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8812908992306927"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def entropy(target = data[:,-1]):\n",
    "    '''\n",
    "    Calculate the entropy of a specific column in the data set\n",
    "    1) accepts a vector\n",
    "    \n",
    "    returns the entropy\n",
    "    '''\n",
    "    entropy = 0.0\n",
    "    values, counts = np.unique(target,return_counts = True)\n",
    "    for i in range(0,len(values)):\n",
    "        entropy = np.sum((-1.0*counts[i]/sum(counts))*np.log2(1.0*counts[i]/sum(counts)) ) + entropy\n",
    "    return entropy # , values, counts\n",
    "\n",
    "\n",
    "entropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02295208771298607,\n",
       " 6.0,\n",
       " [[0.865733522695209, 0.0],\n",
       "  [0.8811032678472634, 1.0],\n",
       "  [0.8767253119276491, 2.0],\n",
       "  [0.8799161341423124, 3.0],\n",
       "  [0.8736695709744837, 4.0],\n",
       "  [0.8785317651150599, 5.0],\n",
       "  [0.8583388115177066, 6.0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Information Gain \n",
    "\"\"\"\n",
    "\n",
    "def IG(data, feature, target = -1 ):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset\n",
    "    Params:\n",
    "    1) data = The dataset \n",
    "    2) feature = the column index for which the information gain will be calculated\n",
    "    3) target = the column index of the information\n",
    "    \n",
    "    Categorical\n",
    "        If the feature only has two unique values the function will return the IG and a string 'cat'\n",
    "    \n",
    "    Non- Categorical \n",
    "        If there are more than two unique features the function will return the maximum IG, the value at which the max IG occurs and a list of the weighted average Entropy\n",
    "    \n",
    "    \"\"\"    \n",
    "    #data = np.array(data)\n",
    "    #Calculate the entropy of the total dataset\n",
    "    target_entropy = entropy(data[:,target])\n",
    "    \n",
    "    ##Calculate the entropy of the dataset\n",
    "    \n",
    "    #Calculate the values and the corresponding counts for the split attribute \n",
    "    values,counts= np.unique(data[:, feature],return_counts=True)\n",
    "    #print(values, counts)\n",
    "    #Calculate the weighted entropy for categorical values\n",
    "    w_entropy = 0.0\n",
    "    if len(values) ==2:\n",
    "        \n",
    "        for i in range(0,len(values)): \n",
    "            w_entropy = (1.0*counts[i]/sum(counts))*entropy(data[:,target][data[:,feature] == values[i]]) + w_entropy\n",
    "        #Calculate the information gain\n",
    "        IG = target_entropy - w_entropy\n",
    "        #print(target_entropy, w_entropy, target_entropy - w_entropy )\n",
    "        return IG, str('cat')\n",
    "    \n",
    "    # return the weighted entropys for noncategorical values\n",
    "    else:    \n",
    "        l =[]\n",
    "        for i in range(1,len(values)): \n",
    "                #print counts[:i]\n",
    "                #print counts[i:]\n",
    "                #print values[i-1]\n",
    "                \n",
    "            l.append([((1.0*sum(counts[:i])/sum(counts))*entropy(data[:,target][data[:,feature] <= values[i-1]]) + (1.0*sum(counts[i:])/sum(counts))*entropy(data[:,target][data[:,feature] > values[i-1]])), values[i-1]]) \n",
    "        w_entropy = min(l)\n",
    "\n",
    "\n",
    "        #Calculate the information gain\n",
    "        split = w_entropy[1]\n",
    "        IG = target_entropy - w_entropy[0]\n",
    "        #print(target_entropy, w_entropy, target_entropy - w_entropy )\n",
    "        return IG, split, l\n",
    "\n",
    "IG(data,4,-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9010989010989011, 1.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Start Gini\n",
    "'''\n",
    "\n",
    "\n",
    "def G(data, feature =0, target = -1):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset\n",
    "    Params:\n",
    "    1) data = The dataset \n",
    "    2) feature = the column index for which the information gain will be calculated\n",
    "    3) target = the column index of the information\n",
    "    \n",
    "    Categorical\n",
    "        If the feature only has two unique values the function will return the IG and a string 'cat'\n",
    "    \n",
    "    Non- Categorical \n",
    "        If there are more than two unique features the function will return the maximum IG, the value at which the max IG occurs and a list of the weighted average Entropy\n",
    "    \n",
    "    \"\"\" \n",
    "    gini = 0\n",
    "    values,counts= np.unique(data[:, feature],return_counts=True)\n",
    "    if len(values) ==2:\n",
    "        for i in [0,1]:\n",
    "            gini = gini + (1.0*counts[i]/sum(counts))* (1-(sum(data[:,target][data[:,feature] == values[i]])/len(data[:,target][data[:,feature] == values[i]]))**2)\n",
    "        return gini, [i]\n",
    "\n",
    "    else:\n",
    "        l = []\n",
    "        for i in range(1,len(values)):\n",
    "            l.append(((1.0*sum(counts[:i])/sum(counts))* (1-(sum(data[:,target][data[:,feature] <= values[i-1]])/len(data[:,target][data[:,feature] <= values[i-1]]))**2)\n",
    "             +(1.0*sum(counts[i:])/sum(counts))* (1-(sum(data[:,target][data[:,feature] > values[i-1]])/len(data[:,target][data[:,feature] > values[i-1]]))**2), values[i-1]))\n",
    "        gini = min(l)    \n",
    "        return gini\n",
    "G(data,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21, 4.0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "Start CART\n",
    "'''\n",
    "def CART(data, feature = 0, target = -1):\n",
    "    \"\"\"\n",
    "    Calculate the information gain of a dataset\n",
    "    Params:\n",
    "    1) data = The dataset \n",
    "    2) feature = the column index for which the information gain will be calculated\n",
    "    3) target = the column index of the information\n",
    "    \n",
    "\n",
    "    \"\"\" \n",
    "    \n",
    "    \n",
    "    values,counts= np.unique(data[:, feature],return_counts=True)\n",
    "    \n",
    "    CART = []\n",
    "    for i in range(1,len(values)):\n",
    "        cy0 = sum(data[:,target][data[:,feature] <= values[i-1]])/len(data[:,target][data[:,feature] <= values[i-1]])\n",
    "        cy1 = sum(data[:,target][data[:,feature] > values[i-1]])/len(data[:,target][data[:,feature] > values[i-1]])\n",
    "        \n",
    "        CART.append([abs(cy0 - cy1)*2.0*(1.0*len(data[:,target][data[:,feature] > values[i-1]])*len(data[:,target][data[:,feature] <= values[i-1]])) / (len(data)**2), values[i-1]])\n",
    "    return max(CART)\n",
    "\n",
    "\n",
    "CART(data, 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "{\"IG\",\"G\",\"CART\"}\n",
    "bestsplit(D, criterion)\n",
    "'''\n",
    "\n",
    "def bestsplit(data, criterion = \"IG\"):\n",
    "   \n",
    "    ''' IG '''    \n",
    "    if criterion == \"IG\":\n",
    "        ig = []\n",
    "        for i in range(0,10):\n",
    "            ig.append([IG(data,i, -1),i])\n",
    "        feature =  max(ig)[1]\n",
    "        x,value,z = max(ig)[0]\n",
    "        return (feature, value)\n",
    "    \n",
    "    \n",
    "    ''' GINI '''\n",
    "    if criterion == \"G\":\n",
    "        g = []\n",
    "        for i in range(0,10):\n",
    "            g.append( (G(data,i, -1),i))\n",
    "\n",
    "        feature = min(g)[1]\n",
    "        x,value = min(g)[0]\n",
    "        return (feature, value)\n",
    "\n",
    "\n",
    "    '''CART'''\n",
    "    if criterion == \"CART\":\n",
    "        cart = []\n",
    "        for i in range(0,10):\n",
    "            cart.append((CART(data,i, -1) , i))\n",
    "        feature =  max(cart)[1]\n",
    "        x,value = max(cart)[0]   \n",
    "        return (feature, value)\n",
    "        \n",
    "    else:\n",
    "        print(\" criterion should equal one of the following: IG,G,CART\" )\n",
    "\n",
    "bestsplit(data, criterion = \"CART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_data = pd.read_csv('test data hw2.csv', header = None)\n",
    "test_data.head()\n",
    "test_data = np.array(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [1, 0.0, False],\n",
       " [1, 1.0, True],\n",
       " [1, 1.0, True],\n",
       " [1, 0.0, False],\n",
       " [1, 1.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "classifyIG(train, test) \n",
    "'''\n",
    "\n",
    "def classifyIG(train = data, test = test_data):\n",
    "    '''\n",
    "    Make predictions based on the information gain classifier\n",
    "    1) the training data\n",
    "    2) the test data\n",
    "    3) assumes the target column is -1\n",
    "    function calls best split, then determines which binary classifier \n",
    "    to assign to the greater than, or less than. finally it \n",
    "    \n",
    "    '''\n",
    "    f, v =  bestsplit(data, criterion = \"IG\")\n",
    "    \n",
    "    high = sum(data[:,-1][data[:,f] > v]) / len(data[:,-1][data[:,f] > v])\n",
    "    low = sum(data[:,-1][data[:,f] <= v]) / len(data[:,-1][data[:,f] <= v])\n",
    "    \n",
    "    if high > low:\n",
    "        high = 1\n",
    "        low = 0\n",
    "    else:\n",
    "        high = 0\n",
    "        low = 1\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[:,f][i] > v:\n",
    "            pred.append([high, test_data[:,-1][i], high == test_data[:,-1][i] ])\n",
    "        if test_data[:,f][i] <= v:\n",
    "            pred.append([low, test_data[:,-1][i], low == test_data[:,-1][i]] )\n",
    "    return pred\n",
    "classifyIG()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [1, 1.0, True],\n",
       " [1, 1.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 1.0, False],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "classifyG(train, test),\n",
    "'''\n",
    "\n",
    "\n",
    "def classifyG(train = data, test = test_data):\n",
    "    '''\n",
    "    Make predictions based on the information gain classifier\n",
    "    1) the training data\n",
    "    2) the test data\n",
    "    3) assumes the target column is -1\n",
    "    function calls best split, then determines which binary classifier \n",
    "    to assign to the greater than, or less than. finally it \n",
    "    \n",
    "    '''\n",
    "    f, v =  bestsplit(data, criterion = \"G\")\n",
    "    \n",
    "    high = sum(data[:,-1][data[:,f] > v]) / len(data[:,-1][data[:,f] > v])\n",
    "    low = sum(data[:,-1][data[:,f] <= v]) / len(data[:,-1][data[:,f] <= v])\n",
    "    \n",
    "    if high > low:\n",
    "        high = 1\n",
    "        low = 0\n",
    "    else:\n",
    "        high = 0\n",
    "        low = 1\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[:,f][i] > v:\n",
    "            pred.append([high, test_data[:,-1][i], high == test_data[:,-1][i] ])\n",
    "        if test_data[:,f][i] <= v:\n",
    "            pred.append([low, test_data[:,-1][i], low == test_data[:,-1][i]] )\n",
    "    return pred\n",
    "\n",
    "classifyG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True],\n",
       " [1, 1.0, True],\n",
       " [1, 1.0, True],\n",
       " [0, 0.0, True],\n",
       " [1, 1.0, True],\n",
       " [0, 0.0, True],\n",
       " [0, 0.0, True]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "classifyCART(train, test)\n",
    "'''\n",
    "def classifyCART(train = data, test = test_data):\n",
    "    '''\n",
    "    Make predictions based on the information gain classifier\n",
    "    1) the training data\n",
    "    2) the test data\n",
    "    3) assumes the target column is -1\n",
    "    function calls best split, then determines which binary classifier \n",
    "    to assign to the greater than, or less than. finally it \n",
    "    \n",
    "    '''\n",
    "    f, v =  bestsplit(data, criterion = \"CART\")\n",
    "    \n",
    "    high = sum(data[:,-1][data[:,f] > v]) / len(data[:,-1][data[:,f] > v])\n",
    "    low = sum(data[:,-1][data[:,f] <= v]) / len(data[:,-1][data[:,f] <= v])\n",
    "    \n",
    "    if high > low:\n",
    "        high = 1\n",
    "        low = 0\n",
    "    else:\n",
    "        high = 0\n",
    "        low = 1\n",
    "    \n",
    "    pred = []\n",
    "    \n",
    "    for i in range(len(test_data)):\n",
    "        if test_data[:,f][i] > v:\n",
    "            pred.append([high, test_data[:,-1][i], high == test_data[:,-1][i] ])\n",
    "        if test_data[:,f][i] <= v:\n",
    "            pred.append([low, test_data[:,-1][i], low == test_data[:,-1][i]] )\n",
    "    return pred\n",
    "\n",
    "classifyCART()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
